---
title: "Кластеризация игроков из FIFA 22"
output:
    html_document:
        #folding of code
        code_folding: show
        #highliting of the code
        highlight: tango
        #theme of the document (see bootswatch.com)
        #other nice variants:
        ##“default”, “cerulean”, “journal”, “flatly”, “darkly”,
        ##“readable”, “spacelab”, “united”, “cosmo”, “lumen”,
        ##“paper”, “sandstone”, “simplex”, “yeti”
        theme: readable
        #table of contents
        toc: yes
        #floating table of contents
        toc_float:
          #collapsed subsections
          collapsed: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Введение

Хотим провести кластеризацию футбольных игроков из датасета футбольного симулятора FIFA 22.

Футболисты играют на разных позициях, однако такие обобщения позиций, как атака, полузащита, и защита, весьма неточны и по тем же причинам не указываются в данных. В то же время, такие обобщения весьма полезны для простого описания для игрока.

Наше предположение состоит в том, что на основании рейтингов игроков по различным характеристикам кластеризация поможет достаточно неплохо различать игроков атаки, полузащиты, и защиты.

## Описание и чистка

Начнём с библиотек.

```{r}
#install.packages(c("knitr", "kableExtra", "magick",
#                   "ggplot2", "reshape2", "viridis",
#                   "stringr", "FactoMineR", "factorextra",
#                   "kohonen", "mclust", "dbscan", "easyr"))
library(knitr) 
library(kableExtra) #красивые html таблицы
library(magick)     #работа с картинками
library(ggplot2)    #графики
library(reshape2)   #работа с датафреймом
library(viridis)    #палитра
library(stringr)    #работа с текстом
library(FactoMineR) #факторный анализ
library(factoextra) #факторный анализ
library(kohonen)    #self-organised maps/SOM 
library(mclust)     #
library(dbscan)     #DBscan метод
library(easyr)
```

Читаем датасет из csv файла и смотрим на размерность.

```{r}
players_full <- read.csv("players_22.csv") #полный датафрейм
dim(players_full)
```

На примере двух известных футболистов покажем, какие переменные у нас имеются.
Вот так, например, выглядит строчка для Лионеля Месси:

```{r}
cbind(1:107,t(players_full[c(1,3),])) %>% kbl() %>% kable_paper("hover", full_width = F, position = "left")
```

Конечно, в дальнейшем отберём именно те признаки, которые предположительно помогут различать позицию игрока.

# Отбор игроков

Так как мы занимаемся кластеризацией, у нас по результатам не будет возможности автоматически проверить результаты работы алгоритмов.
Поэтому важно, чтобы результаты были осмысленными хотя бы для тех случаев, которые нам неплохо знакомы. 
Для этого возьмём две группы игроков, которые помогут убедиться в разумности построенных моделей:

- Российские игроки
- Лучшие игроки мира (по общему рейтингу FIFA)

Всегда возникает обоснованное опасение, что кластеризация произойдёт с учётом общего уровня игроков (например, для топовых игроков кластеризация получилась хорошо, а для "средних" игроков всё перемешалось), поэтому анализировать результаты на основе лишь топовых игроков не совсем корректно.
Российские игроки в целом представлены равномерно по всей таблице, что позволяет оценивать результаты на основе наших знаний.

# Россия

Найдём всех и посмотрим на табличку. Эти игроки нам пригодятся для того, чтобы увидеть, куда они попали после кластеризации. Ещё уберём тех игроков, для которых нет информации о зарплате (у них не фиксирован клуб и лига, это понадобится позже).

```{r}
nashi_parni <- which(players_full$nationality == "Russia" & players_full$value_eur != 0)
url_nashi <- as.character(players_full$player_url[nashi_parni])
#далее то, что нужно для таблицы
cbind(players_full[nashi_parni, c(3,14,15,17,6,7,8,9)], "") %>% kbl() %>% kable_paper("hover", full_width = F, position = "left") %>%
    column_spec(6, color = "black", background = spec_color(players_full[nashi_parni, 6])) %>%
    column_spec(7, color = "black", background = spec_color(players_full[nashi_parni, 7])) %>%
    column_spec(8, color = "black", background = spec_color(players_full[nashi_parni, 8])) %>%
    column_spec(9, color = "black", background = spec_color(players_full[nashi_parni, 9])) %>%
    column_spec(4, color = spec_color(as.integer(players_full[nashi_parni, 15]))) %>%
    column_spec(2, bold = T, link = url_nashi)
```

Русских здесь столько: `r length(nashi_parni)`.

# Мир

Возьмём 50 самых лучших по оценке overall в FIFA футболистов (первые 50 строк).

```{r}
top_world <- 1:50
url_world <- as.character(players_full$player_url[top_world])
cbind(1:50, players_full[top_world, c(3,14,15,17,6,7,8,9)]) %>% kbl() %>% kable_paper("hover", full_width = F, position = "left") %>%
    column_spec(6, color = "black", background = spec_color(players_full[top_world, 6])) %>%
    column_spec(7, color = "black", background = spec_color(players_full[top_world, 7])) %>%
    column_spec(8, color = "black", background = spec_color(players_full[top_world, 8])) %>%
    column_spec(9, color = "black", background = spec_color(players_full[top_world, 9])) %>%
    column_spec(4, color = spec_color(as.integer(players_full[top_world, 15]))) %>%
    column_spec(2, bold = T, link = url_world)
```

# Кластеризация: первичные соображения 

Позиций в футболе достаточно много, особенно если рассматривать в классификации, которая дана здесь и в таблице.

```{r}
unique(players_full$club_position)
```

R и L — right и left, F и B — forward и back, C — center, S - striker

![](positions.jpeg)

Если не учитывать голкиперов, то обычно мы говорим о защите, полузащите и нападении.
В данном датасете присутствуют характеристики, которые _потенциально_ могут помочь в определении предположительной позиции.

Давайте посмотрим, о каких характеристиках идёт речь:
```{r}
skills_vars <- c(35:40,41:74)
names(players_full[,skills_vars])
```

Кажется, что эти характеристики должны хорошо различать атакующих игроков от игроков защиты и полузащиты. Полузащиту в данном случае можно воспринимать как универсальных игроков. Здесь нет намёка на правый/левый фланг и правша/левша, поэтому надеемся, что этот фактор не будет влиять на формирование кластеров.

**Для того, чтобы кластеризация не пошла по возрасту/потенциалу/общему уровню игры/стоимости, эти признаки мы тоже не включаем.**

Так как некоторые характеристик для голкиперов отсутствуют, да и явно есть отличие между вратарями и полевыми игроками, мы изымем их из рассмотрения. Характеристики, которые начинаются с "goalkeeping" мы оставим, они могут помочь различать защитников, которые по долгу службы должны участвовать в защите ворот.

```{r}
goalkeepers <- str_detect(players_full$player_positions, "GK")
sum(goalkeepers)
```

Не так их и много.

Ещё одна проблема заключается в том, что выборка большая и может включать в себя потенциальные неоднородности, которые хотелось бы избежать. Например, в низших лигах границы между игроками могут быть размыты сильнее. Посмотрим, сколько игроков останется, если оставим только игроков команд высших лиг.

```{r}
top_leagues <- (players_full$league_level == 1)
sum(top_leagues, na.rm = TRUE)
```

Также, по этим признакам у нас не должно быть NA, уберём их позже, их немного.

Таким образом, остаётся столько футболистов:

```{r}
sum(top_leagues & !goalkeepers, na.rm = TRUE)
```

# Первичный анализ

Признаков много, поэтому проведём минимальный анализ. 
Сделаем два датафрейма, один с интересующими нас признаками, другой — с общей информацией об игроке, чтобы потом удобно было анализировать результат. NA уберём, как обещали.

```{r}
players <- players_full[top_leagues & !goalkeepers, skills_vars]
players <- na.omit(players)
dim(players)
players_info <- players_full[top_leagues & !goalkeepers, c(3,6,7,8,9,14,17,15,22,2)]
players_info <- na.omit(players_info)
dim(players_info)
num_players <- nrow(players)
```

## Summary по признакам {.tabset .tabset-pills}

```{r}
summary(players)
```

### Основные переменные

```{r}
players_m <- melt(players[,1:6]) 
p <- ggplot(data = players_m, aes(y=variable, x=value, fill = variable, alpha = 0.7)) + 
             geom_boxplot() + geom_violin() + scale_fill_manual(values = viridis(6)) + guides(fill = "none")
p 
```

### Атака

```{r}
players_m <- melt(players[,7:11]) 
p <- ggplot(data = players_m, aes(y=variable, x=value, fill = variable, alpha = 0.7)) + 
             geom_boxplot() + geom_violin() + scale_fill_manual(values = viridis(6)) + guides(fill = "none")
p 
```

### Опыт

```{r}
players_m <- melt(players[,12:16]) 
p <- ggplot(data = players_m, aes(y=variable, x=value, fill = variable, alpha = 0.7)) + 
             geom_boxplot() + geom_violin() + scale_fill_manual(values = viridis(6)) + guides(fill = "none")
p 
```

### Движение

```{r}
players_m <- melt(players[,17:21]) 
p <- ggplot(data = players_m, aes(y=variable, x=value, fill = variable, alpha = 0.7)) + 
             geom_boxplot() + geom_violin() + scale_fill_manual(values = viridis(6)) + guides(fill = "none")
p 
```

### Энергия

```{r}
players_m <- melt(players[,22:26]) 
p <- ggplot(data = players_m, aes(y=variable, x=value, fill = variable, alpha = 0.7)) + 
             geom_boxplot() + geom_violin() + scale_fill_manual(values = viridis(6)) + guides(fill = "none")
p 
```

### Ментальность

```{r}
players_m <- melt(players[,27:32]) 
p <- ggplot(data = players_m, aes(y=variable, x=value, fill = variable, alpha = 0.7)) + 
             geom_boxplot() + geom_violin() + scale_fill_manual(values = viridis(6)) + guides(fill = "none")
p 
```

### Защита

```{r}
players_m <- melt(players[,33:35]) 
p <- ggplot(data = players_m, aes(y=variable, x=value, fill = variable, alpha = 0.7)) + 
             geom_boxplot() + geom_violin() + scale_fill_manual(values = viridis(6)) + guides(fill = "none")
p 
```

### На воротах

```{r}
players_m <- melt(players[,36:40]) 
p <- ggplot(data = players_m, aes(y=variable, x=value, fill = variable, alpha = 0.7)) + 
             geom_boxplot() + geom_violin() + scale_fill_manual(values = viridis(6)) + guides(fill = "none")
p 
```

Как можно видеть, многие из приведённых графиков бимодальны, например, defending и attacking, что может быть хорошим знаком того, что кластеризация у нас получится (и может даже в нормальной модели).

Что касается вратарских качеств: их, по всей видимости можно (и нужно) убрать, они вряд ли нам помогут.

```{r}
players <- players[, -c(36:40)]
```


## Факторный анализ

Попробуем сократить размерность пространства признаков и посмотрим на biplot.

```{r}
res <- PCA(players, scale.unit = TRUE, graph = FALSE, ncp = 5)
fviz_pca_var(res)
res$var$coord %>% kbl() %>% kable_paper("hover", full_width = F, position = "left") %>%
    column_spec(2, color = "black", background = spec_color(abs(res$var$coord[,1]))) %>%
    column_spec(3, color = "black", background = spec_color(abs(res$var$coord[,2])))
```

```{r}
fviz_eig(res, addlabels = TRUE)
```

Первый фактор, по всей видимости, характеризует атакующую игру, а второй — защиту.
Первые две компоненты неплохо описывают дисперсию признаков, поэтому плоскость первых двух компонент весьма полезна для дальнейшей интерпретации.

Построим biplot и найдём некоторых игроков, чтобы интерпретировать полученный результат.

```{r}
fviz_pca_biplot(res,
                label = "all",
                col.ind = (viridis(3))[1],
                col.var = (viridis(3))[2],
                )
bestest <- c(1,4,3,5,29,15,23,16,61,47,56,115)
cbind(bestest, as.character(players_info$short_name[bestest]), as.character(players_info$club_position[bestest]))  %>% kbl() %>% kable_paper("hover", full_width = F, position = "left")
```

Нельзя сказать, что получилось однозначно (из-за полузащиты). С Месси (1), Неймаром (4) и Де Брюйне (5, атакующий полузащитник) всё логично, они в атаке.  
Махрез (47) сейчас полузащитник-вингер, однако помимо подключений к атакам, от этих полузащитников требуется защита их игровых зон от проходов крайних защитников и опорных соперника.
Киммих (15) тоже полузащитник. А вот Агуэро (23), вообще говоря, нападающий. 
Родри (56) - опорный полузащитник, поэтому немного странно, что он там, где есть (хотя, опять же, мы видим только двумерную картинку).
Впрочем, общая логика всё же присутствует.

Кстати, нумерация идёт по общему рейтингу, хорошо видим, что слева внизу индексы большие.

**Отчётливо видим, что есть облака точек; можно увидеть два крупных или три поменьше. **

# Кластеризация

Переходим к применению алгоритмов кластеризации.
Рассмотрим несколько известных алгоритмов:

1. Kohonen's Self-Organized Maps

2. Mclust

3. Иерархическая кластеризация

4. $k$ средних

5. DBscan

## SOM

Начнём с самоорганизующихся карт Кохонена, которые широко используются для уменьшения размерности данных.

```{r}
start_time <- Sys.time()
set.seed(56788)
data_matrix <- as.matrix(scale(players))
# Create the SOM Grid - you generally have to specify the size of the 
# training grid prior to training the SOM. Hexagonal and Circular 
# topologies are possible
som_grid <- somgrid(xdim = 20, ydim=20, topo="hexagonal")
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_matrix, 
        grid=som_grid, 
        rlen=3000, 
        alpha=c(0.05,0.01), 
        keep.data = TRUE)
end_time <- Sys.time()
end_time - start_time
```

### Выбор параметров

Начинаем с выбора сетки: все игроки расположатся в одной из 20х20 ячеек. Выбор размера базируется на колиичестве индивидов в каждой ячейке: их должно быть не менее 10 (см. дальше, как это увидеть). 

`rlen` отвечает за число итераций. Число итераций выбирается с использованием графика ниже. 


```{r}
plot(som_model, type="changes")
```

```{r}
plot(som_model, type="count")
```

На данной картинке показано, сколько индивидов находится в каждой из ячеек. Если смотреть на это как на карту, это аналог плотности населения. Красный цвет - в данном случае означает мало.
Если в одной ячейке много индивидов - значит оказалось, что они похожи друг на друга. При необходимости следует увеличивать размерность сетки, чтобы они стали различимыми. У нас есть одна ячейка с 70 индивидами

Это хорошо, что все игроки распределились по ячейкам более менее равномерно. Может быть нужно увеличить карту, чтобы получилось поменьше индивидов на ячейку, но пока оставим так.

### Карты {.tabset .tabset-pills}

Переходим к главным объектам - самим картам.

```{r, warning = FALSE}
#здесь просто текстовые лейблы делаем
labs_som = rep("", nrow(players))
labs_som[1:100] = abbreviate(players_info$short_name[1:100], 10)
labs_som[players_info$nationality == "Russia"] = as.character(players_info$short_name[players_info$nationality == "Russia"])
# это чтобы легче было раглядеть, можно экспортировать в рабочую папку pdf файл
# pdf()
# plot(som_model, type = "mapping", labels = labs_som, cex = 0.3)
# plot(som_model, type = "mapping", labels = labs_som, cex = 0.5, xlim = c(18,20), ylim = c(13,18))
# plot(som_model, type = "mapping", labels = labs_som, cex = 0.5, xlim = c(18,20), ylim = c(11,16))
```

#### Кто где {.tabset}

Для лучшего осознания того, что вообще на этих картах изображено, давайте покажем, в каких ячейках оказались футболисты топ уровня и наши соотечественники (они смешаны).

Здесь неплохо видно, что произошло. Все топовые игроки сместились в левую часть, однако хорошие защитники образовали кластер в правом верхнем углу. 

Если продолжать аналогию с картами, то 

- В левом вернем углу страна продвинутых полузащитников; 
- Тоже слева, но ближе к центру страна продвинутых нападающих;
- Справа вверху страна защитников;
- В центре универсальные молодые игроки. Продвинутых здесь несколько, но не международного класса.

С интерпретацией других мест на карте сложнее. Может станет лучше дальше, когда будем раскрашивать карту по признакам. 

Видим, что некоторая логика у такой карты есть. На вкладках можно чуть получше рассмотреть имена.

##### Общий вид

```{r, warning = FALSE}
plot(som_model, type = "mapping", labels = labs_som, cex = 0.5)
text(x = 1, y = 16, cex = 2, labels = "midfield", col = "green")
text(x = 1, y = 12, cex = 2, labels = "attack", col = "red")
text(x = 16, y = 14.5, cex = 2, labels = "defence", col = "blue")
```

##### Правая часть 

```{r, warning = FALSE}
plot(som_model, type = "mapping", labels = labs_som, cex = 0.5, xlim = c(16,17), ylim = c(14,18))
```

##### Левая часть 

```{r, warning = FALSE}
plot(som_model, type = "mapping", labels = labs_som, cex = 0.5, xlim = c(0,2), ylim = c(14,18))
plot(som_model, type = "mapping", labels = labs_som, cex = 0.5, xlim = c(0,3), ylim = c(10,13))
```

#### Карта с раскрасками

Раскрасим ячейки по признакам, а также разделим карту на части, максимально отдалённые друг от друга, с помощью  жирной линии (для этого используется иерархическая кластеризация, см. комментарии).

```{r, warning = FALSE}
coolBlueHotRed <- function(n, alpha = 1) {rainbow(n, end=4/6, alpha=alpha)[n:1]}
#k есть число желаемых групп для разделения
som.hc <- cutree(hclust(object.distances(som_model, "codes")), k=2)
#pdf("heatmapkoh")
par(mfrow = c(2,3))
plot(som_model, type = "property", 
     property = getCodes(som_model)[, 1], main = names(players)[1], palette.name = coolBlueHotRed)
add.cluster.boundaries(som_model, som.hc, lwd = 4)
plot(som_model, type = "property", 
     property = getCodes(som_model)[, 2], main = names(players)[2], palette.name = coolBlueHotRed)
add.cluster.boundaries(som_model, som.hc, lwd = 4)
plot(som_model, type = "property", 
     property = getCodes(som_model)[, 3], main = names(players)[3], palette.name = coolBlueHotRed)
add.cluster.boundaries(som_model, som.hc, lwd = 4)
plot(som_model, type = "property", 
     property = getCodes(som_model)[, 4], main = names(players)[4], palette.name = coolBlueHotRed)
add.cluster.boundaries(som_model, som.hc, lwd = 4)
plot(som_model, type = "property", 
     property = getCodes(som_model)[, 5], main = names(players)[5], palette.name = coolBlueHotRed)
add.cluster.boundaries(som_model, som.hc, lwd = 4)
plot(som_model, type = "property", 
     property = getCodes(som_model)[, 6], main = names(players)[6], palette.name = coolBlueHotRed)
add.cluster.boundaries(som_model, som.hc, lwd = 4)

```

Можно долго смотреть и анализировать, что получилось. 

Если посмотреть на раскраску по shooting, то неудивительно, что в левой части расположились практически все атакующие игроки. Поднимаясь слева наверх, видим улучшение по параметру передач, физической форме, темпу, и более высокие показатели по защите, при этом немного ухудшается shooting - чистая качественная полузащита. С защитой тоже всё понятно - лучшие - в правом верхнем углу.

И так далее...

## Model-based пример: `mclust`

Так как метод встречался ранее, пройдёмся по нему быстро.
Предполагается смесь нескольких нормальных распределений.

Будем использовать известную библиотеку `mclust()`, которая строит сразу множество вариантов моделей кластеризации.

```{r}
players_mclust <- Mclust(players, G = 1:4)
```

Параметр G отвечает за число кластеров. В данном случае будут строиться всевозможные модели от 1 до 4 кластеров.

Здесь посмотрим на тот выбор, который делает функция `mclust()`. Этот выбор основывается на посчитанных характеристиках качества модели BIC и ICL. Так как нам известно, что значения BIC и ICL есть случайные числа, можно посмотреть какие ещё варианты кластеризации близки по этим значениям.

```{r}
summary(players_mclust)
```

Метод выбрал разбиение на 9 кластеров, но это много для нас (убрал эту часть для скорости).

*Наш выбор* основан на совокупности факторов:

1. Значение байесовского информационного критерия модели (BIC) (больше --- лучше). Заметим, что значение BIC есть случайная величина, а значит будет весьма осмысленным рассмотреть несколько моделей с похожим BIC и разным числом кластеров и параметров.

2. Число кластеров и число оцениваемых параметров
Заметим здесь, что при сопоставимом значении BIC будем выбирать наиболее простую модель с наименьшим числом оцениваемых параметров, так как чем меньше параметров приходится оценивать, тем меньше будет дисперсия соответствующих оценок при фиксированном размере выборки. Мы хотели бы получить до четырёх кластеров.

Посмотрим на все BIC, построим график.
```{r}
playersBIC <- mclustBIC(players, G = 1:4)
bic_table <- playersBIC[,]
colnames(bic_table) <- colnames(playersBIC)
rownames(bic_table) <- 1:nrow(bic_table)
```

```{r}
bic_table[1:4,] %>% kbl() %>% kable_paper("hover")
plot(playersBIC, G = 1:4, legendArgs = list(x = "bottomright", ncol = 5))
```

Выбрали модель `VVV, 3` (VVV означает, что эллипсоиды распределений вообще никаким образом не совпадают (разный поворот, разный объём, и тд), это максимальное количество параметров)

```{r}
players_mclust <- Mclust(players, G = 3, modelNames = c("VVV"))
summary(players_mclust)
```

На основании наших предположений и графика с главными компонентами можем именовать классы. Построим биплот, чтобы оценить результат визуально.

```{r}
classes_mclust <- as.factor(players_mclust$classification)
table(players_mclust$classification)/num_players
levels(classes_mclust) <- c("Defence","Midfielder","Attack")
fviz_pca_biplot(res,
                label = "all",
                col.ind = classes_mclust,
                legend.title = "Players")
```

### Uncertainty

Качество кластеров можно оценить с помощью меры `uncertainty`, которая вычисляется так: из единицы вычитается вероятность наиболее вероятного класса. Uncertainty должна быть малой для наибольшего числа индивидов.
Это весьма неплохо показывает, насколько классы пересекаются.

Мера встроена в полученный объект от mclust.
Посмотрим на различные квантили:

```{r}
quantile(players_mclust$uncertainty, probs =c(0.6, 0.7, 0.8, 0.9, 0.95, 0.975, 0.99, 0.995))
```

Видим, что у абсолютного большинства индивидов мера uncertainty мала (у $95\%$ индивидов мера меньше 0.25, что существенно лучше наихудшего возможного исхода в нашем случае $G=3$: $0.666$), что хорошо оценивает работу метода.

Чтобы можно было сравнивать все методы, посчитаем within SS/between SS
```{r}
# Subtract each value from the grand mean and get the number of observations in each cluster.
data.cent <- scale(players, scale=FALSE)
nrows <- table(classes_mclust)

TSS <- sum(data.cent^2)

WSS <- sapply(split(players, classes_mclust), function(x) sum(scale(x, scale=FALSE)^2))

BSS <- TSS - sum(WSS)

gmeans <- sapply(split(players, classes_mclust), colMeans)
means <- colMeans(players)
BSS <- sum(colSums((gmeans - means)^2) * nrows)

BSS/TSS
```

### Мир
Посмотрим на отдельныx игроков в таблице:

```{r, echo=FALSE}
players_top <- sort(c(bestest, 82, 37, 42, 11 , 38 , 14 , 24 , 30 , 84, 85))
cbind(rate = rownames(players[players_top,]), name = as.character(players_info$short_name[players_top]), position = as.character(players_info$club_position[players_top]), mclust = as.character(classes_mclust)[players_top]) %>% kbl() %>% kable_paper(full_width = F, "hover") %>%
    column_spec(4, color = "white", background = spec_color(as.numeric(classes_mclust[players_top]))) %>%
    column_spec(2, color = "blue", bold = T, link = players_info$player_url[players_top])
```

### Россия

```{r}
russian <- (players_info$nationality == "Russia")
cbind(rate = rownames(players[russian,]), name = as.character(players_info$short_name[russian]), position = as.character(players_info$club_position[russian]), mclust = as.character(classes_mclust)[russian]) %>% kbl() %>% kable_paper(full_width = F, "hover") %>%
    column_spec(4, color = "white", background = spec_color(as.numeric(classes_mclust[russian]))) %>%
    column_spec(2, color = "blue", bold = T, link = players_info$player_url[russian])
```

Видим множество разумных совпадений.

## Про выбор расстояния

```{r}
plot(1:40, players[1,], "l", col = "red", xlab = "variable", ylab = "points")
lines(1:40, players[2,], col = "red")
lines(1:40, players[1033,], col = "red", lty = 2)
lines(1:40, players[11,], col = "blue")
lines(1:40, players[12,], col = "blue")
lines(1:40, players[3180,], col = "blue", lty = 2)
cor(t(players[c(1,2, 1033, 16,15, 3180),]))
dist((players[c(1,2, 1033, 16,15, 3180),]))
legend("bottom", legend = c("Messi, 1", "Lewandowski, 2", "Smolov, 1033", "Casemiro, 15", "Van Dijk, 16", "Kudryashov, 3180"),  col = c("red", "red","red", "blue", "blue", "blue"), lwd = 1, lty = c(1,1,2,1,1,2))
```

## Иерархическая кластеризация

TODO:: добавить entanglement
https://uc-r.github.io/hc_clustering

```{r}
players_dist <- as.dist(1 - cor(t(players)))
players_hclust <- hclust(players_dist, method="complete")
plot(players_hclust, labels = labs_som, cex = 0.4, main = "Dendrogram (Complete linkage)")
```

```{r}
classes_hclust <- cutree(players_hclust, k = 3)
classes_hclust <- as.factor(classes_hclust)
levels(classes_hclust) <- c("Attack", "Midfielder", "Defence")
table(classes_hclust)/num_players
```

Кластер Defence стал значительно меньше (по сравнению с mclust).

Посмотрим на биплот, убедимся в том, что результат в целом похож на то, что мы видели ранее.

```{r}
fviz_pca_biplot(res,
                label = "all",
                col.ind = classes_hclust,
                legend.title = "Players")
```

### Качество

Здесь опять же надо сделать замечание, что кластеры мы делали с помощью другого функционала (минимизировали корреляцию между индивидами), поэтому то, что приведено дальше — не совсем верно (но для сравнения с другими методами допустимо). 

```{r}
# Subtract each value from the grand mean and get the number of observations in each cluster.
data.cent <- scale(players, scale=FALSE)
nrows <- table(cutree(players_hclust, k = 3))

TSS <- sum(data.cent^2)

WSS <- sapply(split(players, classes_hclust), function(x) sum(scale(x, scale=FALSE)^2))

BSS <- TSS - sum(WSS)

gmeans <- sapply(split(players, classes_hclust), colMeans)
means <- colMeans(players)
BSS <- sum(colSums((gmeans - means)^2) * nrows)

BSS/TSS
```

### Мир

```{r, echo=FALSE}
cbind(rate = rownames(players[players_top,]), name = as.character(players_info$short_name[players_top]), position = as.character(players_info$club_position[players_top]), hclust = as.character(classes_hclust)[players_top]) %>% kbl() %>% kable_paper(full_width = F, "hover") %>%
    column_spec(4, color = "white", background = spec_color(as.numeric(classes_hclust[players_top]))) %>%
    column_spec(2, color = "blue", bold = T, link = players_info$player_url[players_top])
```

### Россия

```{r}
russian <- (players_info$nationality == "Russia")
cbind(rate = rownames(players[russian,]), name = as.character(players_info$short_name[russian]), position = as.character(players_info$club_position[russian]), hclust = as.character(classes_hclust)[russian]) %>% kbl() %>% kable_paper(full_width = F, "hover") %>%
    column_spec(4, color = "white", background = spec_color(as.numeric(classes_hclust[russian]))) %>%
    column_spec(2, color = "blue", bold = T, link = players_info$player_url[russian])
```

## $k$-средних для трёх классов

```{r}
set.seed(28)
num_of_clust <- 3
players_kmeans <- kmeans(players, num_of_clust)
classes_kmeans <- players_kmeans$cluster
```

Число BSS/TSS:
```{r}
players_kmeans$betweenss/(sum(players_kmeans$withinss)+players_kmeans$betweenss)
```

### Мир

```{r, echo=FALSE}
cbind(rate = rownames(players[players_top,]), name = as.character(players_info$short_name[players_top]), position = as.character(players_info$club_position[players_top]), kmeans = as.character(classes_kmeans)[players_top]) %>% kbl() %>% kable_paper(full_width = F, "hover") %>%
    column_spec(4, color = "white", background = spec_color(as.numeric(classes_kmeans[players_top]))) %>%
    column_spec(2, color = "blue", bold = T, link = players_info$player_url[players_top])
```

### Россия

```{r}
russian <- (players_info$nationality == "Russia")
cbind(rate = rownames(players[russian,]), name = as.character(players_info$short_name[russian]), position = as.character(players_info$club_position[russian]), kmeans = as.character(classes_kmeans)[russian]) %>% kbl() %>% kable_paper(full_width = F, "hover") %>%
    column_spec(4, color = "white", background = spec_color(as.numeric(classes_kmeans[russian]))) %>%
    column_spec(2, color = "blue", bold = T, link = players_info$player_url[russian])
```

## DBSCAN

Для DBscan нужен оптимальный радиус окрестности. 
Его можно определить приближённо с помощью kNN графика. 
Датасет у нас большой, но для начала попробуем взять 5 соседей (это станет min pts).

```{r}
dbscan::kNNdistplot(players, k =  3)
abline(h = 55, lty = 2)
```

Возьмём $\varepsilon = 55$.

```{r}
players_dbscan <- dbscan(players, eps = 60, minPts = 3)
```

```{r}
classes_dbscan <- players_dbscan$cluster
fviz_pca_biplot(res,
                label = "all",
                col.ind = factor(classes_dbscan),
                legend.title = "Players")
```

Попытаем счастье, взяв метрику с корреляциями.

```{r}
dbscan::kNNdistplot(players_dist, k = 5)
abline(h = 0.08, lty = 2)
```

```{r}
players_dbscan <- dbscan(players_dist, eps = 0.05, minPts = 5)
classes_dbscan <- players_dbscan$cluster
```

```{r}
classes_dbscan <- players_dbscan$cluster
fviz_pca_biplot(res,
                label = "all",
                col.ind = factor(classes_dbscan),
                legend.title = "Players")
```

# Сравнение по методам

```{r}
cbind(rate = rownames(players[players_top,]), name = as.character(players_info$short_name[players_top]), position = as.character(players_info$club_position[players_top]), mclust = as.character(classes_mclust)[players_top],hclust = as.character(classes_hclust)[players_top], kmeans = as.character(classes_kmeans)[players_top], DBscan = as.character(classes_dbscan)[players_top] ) %>% kbl() %>% kable_paper(full_width = F, "hover") %>%
    column_spec(2, color = "blue", bold = T, link = players_info$player_url[players_top])
```

```{r}
cbind(rate = rownames(players[russian,]), name = as.character(players_info$short_name[russian]), position = as.character(players_info$club_position[russian]), mclust = as.character(classes_mclust)[russian],hclust = as.character(classes_hclust)[russian], kmeans = as.character(classes_kmeans)[russian], DBscan = as.character(classes_dbscan)[russian] ) %>% kbl() %>% kable_paper(full_width = F, "hover") %>%
    column_spec(2, color = "blue", bold = T, link = players_info$player_url[russian])
```




<!-- Отметим, что жанр фильма может состоять из нескольких слов, поэтому в дальнейшем надо будет принимать решение о том, как эту информацию свести к одному слову, чтобы примерно охарактеризовать фильм в целом. -->

<!-- Для некоторых фильмов нет информации об их прибыли, мы их уберём из датасета (это из за того, что для фильмов есть информация по мировому box office, но не по США).  -->

<!-- ```{r} -->
<!-- imdb_na_clean <- na.omit(imdb_full) -->
<!-- dim(imdb_na_clean) -->
<!-- ``` -->

<!-- Осталось 838 фильмов, чего нам вполне достаточно для дальнейшего анализа. Для кластеризации нам будут нужны в численные переменные, кроме года, ещё добавим одну dummy variable, 1 для которой будет означать, что в жанре фильма присутствовало слово "action". -->

<!-- ```{r} -->
<!-- library(stringr) -->
<!-- action <- str_detect(imdb_na_clean$Genre, "Action") -->

<!-- imdb_gen <- cbind(imdb_na_clean, action = action) -->
<!-- names(imdb_gen)[8] <- "Runtime" -->
<!-- names(imdb_gen)[11] <- "Revenue" -->
<!-- row.names(imdb_gen) <- 1:nrow(imdb_gen) -->
<!-- ``` -->

<!-- В предыдущей работе уже разобрались что логарифмировать и какие у нас аутлаеры, приведём здесь без разъяснений соответствующие графики. -->

<!-- ```{r, include = FALSE} -->
<!-- panel.hist <- function(x, ...) -->
<!-- { -->
<!--     usr <- par("usr"); on.exit(par(usr)) -->
<!--     par(usr = c(usr[1:2], 0, 1.5) ) -->
<!--     h <- hist(x, plot = FALSE) -->
<!--     breaks <- h$breaks; nB <- length(breaks) -->
<!--     y <- h$counts; y <- y/max(y) -->
<!--     rect(breaks[-nB], 0, breaks[-1], y, col = "orange", ...) -->
<!-- } -->
<!-- ``` -->

<!-- ```{r} -->
<!-- library(ggplot2) -->
<!-- pairs(~ log(Runtime) + Rating + log(Votes) + log(Revenue) + Metascore, data = imdb_gen, diag.panel = panel.hist, pch = 19,  cex = 0.5) -->
<!-- ``` -->

<!-- Некоторую нелинейность можем заметить на `Rating vs. log(Revenue)`, что может свидетельствовать о возможной неоднородности в данных. -->

<!-- Теперь АГК: -->

<!-- ```{r} -->
<!-- imdb_transf <- data.frame(title = imdb_gen$Title, year = imdb_gen$Year, log_runtime = log(imdb_gen$Runtime), rating = imdb_gen$Rating, log_votes = log(imdb_gen$Votes), log_revenue = log(imdb_gen$Revenue + 0.000001), metascore = imdb_gen$Metascore, ext_genre = imdb_gen$Genre, action = as.numeric(imdb_gen$action)) -->

<!-- library("FactoMineR")  -->
<!-- library("factoextra") -->
<!-- quant_var <- c(3:7) -->
<!-- res <- PCA(imdb_transf[,c(quant_var)], scale.unit = TRUE, graph = FALSE, ncp = 5) -->
<!-- fviz_pca_var(res) -->
<!-- ``` -->

<!-- Также построим biplot и уберём несколько предположительных аутлаеров. -->

<!-- ```{r} -->
<!-- library(viridis) -->
<!-- fviz_pca_biplot(res, -->
<!--                 label = "all", -->
<!--                 col.ind = (viridis(3))[1], -->
<!--                 col.var = (viridis(3))[2], -->
<!--                 legend.title = "Genres") -->
<!-- outliers <- c(59, 287, 204, 223, 210, 704) -->
<!-- imdb_transf$title[outliers] %>% kbl() %>% kable_paper(full_width = FALSE, position = "left", "hover") -->
<!-- imdb_transf <- imdb_transf[-outliers,] -->
<!-- row.names(imdb_transf) <- 1:nrow(imdb_transf) -->
<!-- ``` -->

<!-- ## Кластеризация -->

<!-- ### Model-based -->

<!-- Будем использовать известную библиотеку `mclust()`, которая строит сразу множество вариантов моделей кластеризации. -->

<!-- ```{r} -->
<!-- library(mclust) -->
<!-- imdb_clust <- Mclust(imdb_transf[,c(quant_var)]) -->
<!-- ``` -->

<!-- Здесь посмотрим на тот выбор, который делает функция `mclust()`. Этот выбор основывается на посчитанных характеристиках качества модели BIC и ICL. Так как нам известно, что значения BIC и ICL есть случайные числа, можно посмотреть какие ещё варианты кластеризации близки по этим значениям. -->

<!-- ```{r} -->
<!-- summary(imdb_clust, parameters = TRUE) -->
<!-- plot(imdb_clust, what = "classification") -->
<!-- ``` -->

<!-- *Наш выбор* будет основан на совокупности факторов: -->

<!-- 1. Значение байесовского информ -->

<!-- ационного критерия модели (BIC) (больше --- лучше). Заметим, что значение BIC есть случайная величина, а значит будет весьма осмысленным рассмотреть несколько моделей с похожим BIC и разным числом кластеров и параметров. -->
<!-- 2. Число кластеров и число оцениваемых параметров -->
<!-- Заметим здесь, что при сопоставимом значении BIC будем выбирать наиболее простую модель с наименьшим числом оцениваемых параметров, так как чем меньше параметров приходится оценивать, тем меньше будет дисперсия соответствующих оценок при фиксированном размере выборки. -->

<!-- Посмотрим на все BIC, построим график. -->
<!-- ```{r} -->
<!-- imdbBIC <- mclustBIC(imdb_transf[,c(quant_var)]) -->
<!-- bic_table <- imdbBIC[,] -->
<!-- colnames(bic_table) <- colnames(imdbBIC) -->
<!-- rownames(bic_table) <- 1:nrow(bic_table) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- bic_table[1:4,] %>% kbl() %>% kable_paper("hover") -->

<!-- plot(imdbBIC, G = 1:5, ylim = c(-15000,-12500), legendArgs = list(x = "bottomright", ncol = 5)) -->
<!-- ``` -->

<!-- Так как с увеличением числа кластеров число параметров смеси, которые надо оценить, может значительно возрасти, разумно рассмотреть варианты с меньшим числом компонент, обратив внимание на то, что значения BIC достаточно близки. Рассмотрим близкие по BIC варианты с двумя и тремя компонентами. -->

<!-- Составим список кандидатов по возрастанию числа кластеров и запишем число оцениваемых параметров и BIC: -->

<!-- |Модель| BIC | Число параметров (смесь + средние + объём + форма + поворот)| -->
<!-- |----|----|-----| -->
<!-- |`VVV, 2`|$-12849.14$ | $29 = 1 + 10 + 2 + 8 + 8$ |  -->
<!-- |`VVE, 2`|$-12898.44$ | $25 = 1 + 10 + 2 + 8 + 4$ |  -->
<!-- |`VVV, 3`|$-12816.21$ | $44 = 2 + 15 + 3 + 12 + 12$| -->
<!-- |`VVE, 3`|$-12840.90$ | $36 = 2 + 15 + 3 + 12 + 4$| -->
<!-- |`VVE, 4`|$-12792.01$ | $43 = 3 + 20 + 4 + 12 + 4$| -->

<!-- По упомянутым соображениям о числе оцениваемых параметров и его влиянии на дисперсию оценок можно попробовать выбрать модели `VVV, 2` и `VVE, 2`. -->


<!-- ```{r} -->
<!-- imdbclust1 <- Mclust(imdb_transf[,c(quant_var)], G = 2, modelNames = c("VVV")) -->
<!-- plot(imdbclust1, what = "classification") -->
<!-- summary(imdbclust1) -->

<!-- imdbclust2 <- Mclust(imdb_transf[,c(quant_var)], G = 2, modelNames = c("VVE")) -->
<!-- plot(imdbclust2, what = "classification") -->
<!-- summary(imdbclust2, parameters = TRUE) -->
<!-- ``` -->

<!-- Для дальнейшего анализа также сохраним себе вариант `VVV` с тремя кластерами. -->
<!-- ```{r} -->
<!-- imdbclust3 <- Mclust(imdb_transf[,c(quant_var)], G = 3, modelNames = c("VVV")) -->
<!-- #plot(imdbclust3, what = "classification") -->
<!-- summary(imdbclust3) -->
<!-- ``` -->

<!-- Отличаются они несильно, поэтому выберем вариант с наименьшим числом параметров: `VVE, 2`. -->

<!-- ```{r} -->
<!-- res <- PCA(imdb_transf[,c(quant_var)], scale.unit = TRUE, graph = FALSE, ncp = 5) -->
<!-- fviz_pca_biplot(res, -->
<!--                 label = "all", -->
<!--                 col.ind = imdbclust2$classification, -->
<!--                 legend.title = "Genres") -->
<!-- ``` -->

<!-- Посмотрим на отдельные фильмы в таблице: -->

<!-- ```{r, echo=FALSE} -->
<!-- chosen_movies <- c(1,5,7, 15,21,23,29,31,32,54,56,104,98,99, 46, 376, 569, 229, 159, 182, 537, 775, 792) -->
<!-- cbind(as.character(imdb_transf$title[chosen_movies]), extendedGenre = as.character(imdb_transf$ext_genre[chosen_movies]), genre = as.character(imdb_transf$genre[chosen_movies]), rating = imdb_transf$rating[chosen_movies], revenue = round(imdb_transf$log_revenue[chosen_movies], 3) , votes = round(imdb_transf$log_votes[chosen_movies], 3), cluster = (as.character(imdbclust2$classification))[chosen_movies]) %>% kbl() %>% kable_paper(full_width = T, "hover") %>% column_spec(6, color = "black",  -->
<!--               background = spec_color((imdbclust2$classification)[chosen_movies], alpha = 0.3, option = "E", direction = -1)) %>% column_spec(4, color = "black",  -->
<!--               background = spec_color(round(imdb_transf$log_revenue[chosen_movies], 3), alpha = 0.3, option = "E")) %>% column_spec(5, color = "black",  -->
<!--               background = spec_color(round(imdb_transf$log_votes[chosen_movies], 3), alpha = 0.3, option = "E")) %>% column_spec(3, color = "black",  -->
<!--               background = spec_color(round(imdb_transf$rating[chosen_movies], 3), alpha = 0.3, option = "E"))  -->

<!-- df_imdbb <- cbind(imdb_transf, imdbclust2$classification) -->
<!-- ``` -->

<!-- Если посмотреть на это, то в целом те фильмы, которые не оказались успешными в прокате (или плохой рейтинг, или мало просмотров), категоризуются как 2 класс. -->

<!-- Отметим, что использование модельного метода кластеризации очевидно приводит к не очень удовлетворительным результатам в том числе и из-за того, что нормальность по отдельным (даже логарифмированным) переменным отсутствует. Поэтому ожидаемо, что кластеризация будет находить что-нибудь близкое к нормальному в области высокой плотности, а хвост рассматривать уже как что-то из другого облака. -->


<!-- ### $k$-средних -->

<!-- Нормализуем численные переменные датасета. -->

<!-- ```{r} -->
<!-- imdb_scaled <- cbind.data.frame(title = imdb_transf$title, runtime = scale(imdb_transf$log_runtime), rating = scale(imdb_transf$rating), revenue = scale(imdb_transf$log_revenue), votes = scale(imdb_transf$log_votes), metascore = scale(imdb_transf$metascore)) -->
<!-- ``` -->

<!-- Для метода $k$-средних приходится явно задавать количество кластеров, то есть нужно хотя-бы приблизительно иметь представление о том, что нужно искать. -->

<!-- #### $k$-средних для двух классов -->

<!-- Применим к данным метод $k$-средних для двух классов.  -->

<!-- ```{r} -->
<!-- num_of_clust <- 2 -->
<!-- imdb_kmeans1 <- kmeans(imdb_scaled[,-1], num_of_clust) -->
<!-- ``` -->

<!-- Число BSS/TSS даёт некоторое представление о качестве построенной кластеризации. Единица означала бы идеальную отделимость двух кластеров -->
<!-- ```{r} -->
<!-- imdb_kmeans1$betweenss/(sum(imdb_kmeans1$withinss)+imdb_kmeans1$betweenss) -->
<!-- ``` -->

<!-- В данном случае число достаточно низкое, что и было ожидаемо (если смотреть на matrix plot и на главные компоненты). -->

<!-- Построим попарный скеттерплот с раскраской по кластерам: -->

<!-- ```{r} -->
<!-- library(viridis) -->
<!-- my_cols <- viridis(num_of_clust) -->
<!-- pairs(imdb_scaled[,-1], col = my_cols[imdb_kmeans1$cluster], pch = 19,  cex = 0.5, oma=c(3,3,6,8)) -->
<!-- par(xpd = TRUE) -->
<!-- legend("bottomright", legend = 1:num_of_clust, col = my_cols, pch = 19,  cex = 0.5) -->
<!-- title("Matrix Plot (group by k-means cluster)") -->
<!-- ``` -->

<!-- В данном случае разбиение не очень похоже на то, что мы получили раньше с методом смесей (в методе смесей облака чаще накладывались друг на друга). -->

<!-- #### $k$-средних для трёх классов -->

<!-- Теперь рассмотрим вариант с тремя кластерами. Напомним, что в работе по классификации у нас разбиение было по трём классам: 'drama', 'action', 'comedy'. Интересно, будет ли результат данной кластеризации иметь похожий смысл. -->

<!-- ```{r} -->
<!-- num_of_clust <- 3 -->
<!-- imdb_kmeans2 <- kmeans(imdb_scaled[,-1], num_of_clust) -->
<!-- ``` -->

<!-- Число BSS/TSS: -->
<!-- ```{r} -->
<!-- imdb_kmeans2$betweenss/(sum(imdb_kmeans2$withinss)+imdb_kmeans2$betweenss) -->
<!-- ``` -->

<!-- В данном случае число увеличилось достаточно сильно, что может свидетельствовать о том, что увеличение числа кластеров сделали не зря. -->

<!-- Также, как и в прошлый раз, построим скеттерплот с раскраской: -->

<!-- ```{r} -->
<!-- library(viridis) -->
<!-- my_cols <- viridis(num_of_clust) -->
<!-- pairs(imdb_scaled[,-1], col = my_cols[imdb_kmeans2$cluster], pch = 19,  cex = 0.5, oma=c(3,3,6,8)) -->
<!-- par(xpd = TRUE) -->
<!-- legend("bottomright", legend = 1:num_of_clust, col = my_cols, pch = 19,  cex = 0.5) -->
<!-- title("Matrix Plot (group by k-means cluster)") -->
<!-- ``` -->

<!-- Данная картинка напоминает классификацию по жанрам (по расположениям центров облаков, как минимум). Посмотрим на таблицу, чтобы оценить, насколько хорошо выглядит разбиение без учителя (таблица, конечно, смещена к 1му классу из-за того, что в основном именно там есть известные и популярные фильмы) -->

<!-- ```{r} -->
<!-- cbind(as.character(imdb_transf$title[chosen_movies]), extendedGenre = as.character(imdb_transf$ext_genre[chosen_movies]), genre = as.character(imdb_transf$genre[chosen_movies]), rating = imdb_transf$rating[chosen_movies], revenue = round(imdb_transf$log_revenue[chosen_movies], 3) , votes = round(imdb_transf$log_votes[chosen_movies], 3), cluster = (as.character(imdb_kmeans2$cluster))[chosen_movies]) %>% kbl() %>% kable_paper(full_width = T, "hover") %>% column_spec(6, color = "black",  -->
<!--               background = spec_color((imdb_kmeans2$cluster)[chosen_movies], alpha = 0.3, direction = 1)) %>% column_spec(4, color = "black",  -->
<!--               background = spec_color(round(imdb_transf$log_revenue[chosen_movies], 3), alpha = 0.3, option = "E")) %>% column_spec(5, color = "black",  -->
<!--               background = spec_color(round(imdb_transf$log_votes[chosen_movies], 3), alpha = 0.3, option = "E")) %>% column_spec(3, color = "black",  -->
<!--               background = spec_color(round(imdb_transf$rating[chosen_movies], 3), alpha = 0.3, option = "E"))  -->
<!-- ``` -->

<!-- Можно видеть по этому примеру, что осмысленного разделения по жанрам здесь практически нет. Разве что экшн фильмы кластеризовались вместе с успешными фильмами других жанров, а это скорее сегментация на более/менее успешные фильмы. Это подтверждается и третьим кластером, к которому отнесены относительно малоуспешные фильмы. -->

<!-- #### Сравнение результатов по model-based и k-means -->

<!-- Посмотрим, насколько похожи кластеры, построенные по двум разным методам: model-based и k-means.  -->

<!-- ##### Для двух кластеров -->

<!-- ```{r} -->
<!-- library("MASS") -->
<!-- first <- which(imdbclust2$classification == 1) -->
<!-- imdbclust2$classification[first] = 2 -->
<!-- imdbclust2$classification[-first] = 1 #поменяли классы -->
<!-- ct <- table(imdbclust2$classification, imdb_kmeans1$cluster) -->
<!-- addmargins(ct) %>% kbl() %>% kable_paper("hover", full_width = F, position = "left") -->
<!-- diag(prop.table(ct, 2)) %>% kbl() %>% kable_paper("hover", full_width = F, position = "left")  -->
<!-- ``` -->
<!-- Нельзя сказать, что они сильно похожи друг на друга. Совпадают они чуть более чем на половине наблюдений. -->

<!-- ##### Для трёх кластеров -->

<!-- ```{r} -->
<!-- library("MASS") -->
<!-- ct <- table(imdbclust3$classification, imdb_kmeans2$cluster) -->
<!-- addmargins(ct) %>% kbl() %>% kable_paper("hover", full_width = F, position = "left") -->
<!-- diag(prop.table(ct, 2)) %>% kbl() %>% kable_paper("hover", full_width = F, position = "left")  -->
<!-- ``` -->

<!-- В данном случае можно сказать, что методы оказались весьма близкими в разделении кластеров; совпадение на $80\%$. -->

<!-- ### Иерархический кластерный анализ -->

<!-- Признаки уже стандартизированы, поэтому расстояние между точками измерять будет несложно. -->

<!-- ```{r} -->
<!-- set.seed(1) -->
<!-- labels <- as.character(imdb_scaled[,1]) -->
<!-- more_movies <- c(chosen_movies, sample(1:nrow(imdb_scaled), 30)) -->
<!-- labels[ -more_movies  ] <- "" -->
<!-- ``` -->

<!-- Будем пробовать с разными вариантами слияния кластеров. Подпишем некоторые фильмы на дендрограммах. -->

<!-- Субъективным правилом иерархической кластеризации можно считать следующее: там, где ветка длиннее, там межкластерное расстояние больше, следовательно делить разумно там. Однако как и ожидается, на наших дендрограммах не ожидается хорошей отделимости, потому веточки везде будут достаточно короткими (здесь расстояния не в квадратах). -->

<!-- ##### Расстояние дальнего соседа: -->

<!-- Даже быстрый взгляд на дендрограммы (если посмотреть на некоторые близкие по смыслу "супергеройские" картины, они находятся далеко друг от друга) позволяет сказать, что кластерная структура при выборе такого типа связи здесь очень слабая. -->

<!-- ```{r} -->
<!-- hc <- hclust(dist(imdb_scaled[,-1], "euclidean"), method = "complete") -->
<!-- plot(hc, hang = -10, labels = abbreviate(labels, 15), cex = 0.5) -->
<!-- ``` -->

<!-- ##### Групповое среднее расстояние -->

<!-- Здесь связи кажутся немного более осмысленными и похожими на k-means, что логично. Тем не менее, чёткая структура здесь не проглядывается. -->

<!-- ```{r} -->
<!-- hc <- hclust(dist(imdb_scaled[,-1], "euclidean"), method = "average") -->
<!-- plot(hc, hang = -10, labels = abbreviate(labels, 15), cex = 0.5) -->
<!-- ``` -->

<!-- ##### Center linkage -->

<!-- Здесь как связи рассматриваются связи между центроидами кластеров. На эту дендрограмму смотреть не станем, так как структура слишком сильно переплетена. -->

<!-- ```{r} -->
<!-- hc <- hclust(dist(imdb_scaled[,-1], "euclidean"), method = "centroid") -->
<!-- plot(hc, hang = -10, labels = abbreviate(labels, 15), cex = 0.5) -->
<!-- ``` -->

<!-- ##### Single linkage -->

<!-- Здесь сложно что-нибудь увидеть ввиду того, что кластеры собираются по цепочке, добавляя по одному фильму. -->

<!-- ```{r} -->
<!-- hc <- hclust(dist(imdb_scaled[,-1], "euclidean"), method = "single") -->
<!-- plot(hc, hang = -10, labels = abbreviate(labels, 15), cex = 0.5) -->
<!-- ``` -->



<!-- ## Выводы -->

<!-- В рассмотренном датасете обнаружить хорошо отделимые кластеры не удалось, в данном случае можно лишь сегментировать данные на некоторые смысловые части, которые, в принципе, видны на поверхности.  -->

<!-- В этот раз не использовали текстовую информацию о фильме, информацию про жанры, а также информацию об актёрах и режиссёрах. В дальнейшем было бы интересно использовать метрики, которые дают семантическое расстояние между текстами описания и близость между списками актёров и режиссёров. Тогда, полагаем, классификация без учителя оказалась бы более успешной. -->