---
title: "Кластеризация игроков из FIFA 22"
output:
    html_document:
        #folding of code
        code_folding: show
        #highliting of the code
        highlight: tango
        #theme of the document (see bootswatch.com)
        #other nice variants:
        ##“default”, “cerulean”, “journal”, “flatly”, “darkly”,
        ##“readable”, “spacelab”, “united”, “cosmo”, “lumen”,
        ##“paper”, “sandstone”, “simplex”, “yeti”
        theme: readable
        #table of contents
        toc: yes
        #floating table of contents
        toc_float:
          #collapsed subsections
          collapsed: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Введение

Хотим провести кластеризацию футбольных игроков из датасета футбольного симулятора FIFA 22.

Футболисты играют на разных позициях, однако такие обобщения позиций, как атака, полузащита, и защита, весьма неточны и по тем же причинам не указываются в данных. В то же время, такие обобщения весьма полезны для простого описания для игрока.

Наше предположение состоит в том, что на основании рейтингов игроков по различным характеристикам кластеризация поможет достаточно неплохо различать игроков атаки, полузащиты, и защиты.

## Описание и чистка

Начнём с библиотек.

```{r}
#install.packages(c("knitr", "kableExtra", "magick",
#                   "ggplot2", "reshape2", "viridis",
#                   "stringr", "FactoMineR", "factorextra",
#                   "kohonen", "mclust", "dbscan", "easyr"))
library(knitr) 
library(kableExtra) #красивые html таблицы
library(magick)     #работа с картинками
library(ggplot2)    #графики
library(reshape2)   #работа с датафреймом
library(viridis)    #палитра
library(stringr)    #работа с текстом
library(FactoMineR) #факторный анализ
library(factoextra) #факторный анализ
library(kohonen)    #self-organised maps/SOM 
library(mclust)     #
library(dbscan)     #DBscan метод
library(easyr)
```

Читаем датасет из csv файла и смотрим на размерность.

```{r}
players_full <- read.csv("players_22.csv") #полный датафрейм
dim(players_full)
```

На примере двух известных футболистов покажем, какие переменные у нас имеются.
Вот так, например, выглядит строчка для Лионеля Месси:

```{r}
cbind(1:107,t(players_full[c(1,3),])) %>% kbl() %>% kable_paper("hover", full_width = F, position = "left")
```

Конечно, в дальнейшем отберём именно те признаки, которые предположительно помогут различать позицию игрока.

# Отбор игроков

Так как мы занимаемся кластеризацией, у нас по результатам не будет возможности автоматически проверить результаты работы алгоритмов.
Поэтому важно, чтобы результаты были осмысленными хотя бы для тех случаев, которые нам неплохо знакомы. 
Для этого возьмём две группы игроков, которые помогут убедиться в разумности построенных моделей:

- Российские игроки
- Лучшие игроки мира (по общему рейтингу FIFA)

Всегда возникает обоснованное опасение, что кластеризация произойдёт с учётом общего уровня игроков (например, для топовых игроков кластеризация получилась хорошо, а для "средних" игроков всё перемешалось), поэтому анализировать результаты на основе лишь топовых игроков не совсем корректно.
Российские игроки в целом представлены равномерно по всей таблице, что позволяет оценивать результаты на основе наших знаний.

# Россия

Найдём всех и посмотрим на табличку. Эти игроки нам пригодятся для того, чтобы увидеть, куда они попали после кластеризации. Ещё уберём тех игроков, для которых нет информации о зарплате (у них не фиксирован клуб и лига, это понадобится позже).

```{r}
nashi_parni <- which(players_full$nationality == "Russia" & players_full$value_eur != 0)
url_nashi <- as.character(players_full$player_url[nashi_parni])
#далее то, что нужно для таблицы
cbind(players_full[nashi_parni, c(3,14,15,17,6,7,8,9)], "") %>% kbl() %>% kable_paper("hover", full_width = F, position = "left") %>%
    column_spec(6, color = "black", background = spec_color(players_full[nashi_parni, 6])) %>%
    column_spec(7, color = "black", background = spec_color(players_full[nashi_parni, 7])) %>%
    column_spec(8, color = "black", background = spec_color(players_full[nashi_parni, 8])) %>%
    column_spec(9, color = "black", background = spec_color(players_full[nashi_parni, 9])) %>%
    column_spec(4, color = spec_color(as.integer(players_full[nashi_parni, 15]))) %>%
    column_spec(2, bold = T, link = url_nashi)
```

Русских здесь столько: `r length(nashi_parni)`.

# Мир

Возьмём 50 самых лучших по оценке overall в FIFA футболистов (первые 50 строк).

```{r}
top_world <- 1:50
url_world <- as.character(players_full$player_url[top_world])
cbind(1:50, players_full[top_world, c(3,14,15,17,6,7,8,9)]) %>% kbl() %>% kable_paper("hover", full_width = F, position = "left") %>%
    column_spec(6, color = "black", background = spec_color(players_full[top_world, 6])) %>%
    column_spec(7, color = "black", background = spec_color(players_full[top_world, 7])) %>%
    column_spec(8, color = "black", background = spec_color(players_full[top_world, 8])) %>%
    column_spec(9, color = "black", background = spec_color(players_full[top_world, 9])) %>%
    column_spec(4, color = spec_color(as.integer(players_full[top_world, 15]))) %>%
    column_spec(2, bold = T, link = url_world)
```

# Кластеризация: первичные соображения 

Позиций в футболе достаточно много, особенно если рассматривать в классификации, которая дана здесь и в таблице.

```{r}
unique(players_full$club_position)
```

R и L — right и left, F и B — forward и back, C — center, S - striker

![](positions.jpeg)

Если не учитывать голкиперов, то обычно мы говорим о защите, полузащите и нападении.
В данном датасете присутствуют характеристики, которые _потенциально_ могут помочь в определении предположительной позиции.

Давайте посмотрим, о каких характеристиках идёт речь:
```{r}
skills_vars <- c(35:40,41:74)
names(players_full[,skills_vars])
```

Кажется, что эти характеристики должны хорошо различать атакующих игроков от игроков защиты и полузащиты. Полузащиту в данном случае можно воспринимать как универсальных игроков. Здесь нет намёка на правый/левый фланг и правша/левша, поэтому надеемся, что этот фактор не будет влиять на формирование кластеров.

**Для того, чтобы кластеризация не пошла по возрасту/потенциалу/общему уровню игры/стоимости, эти признаки мы тоже не включаем.**

Так как некоторые характеристик для голкиперов отсутствуют, да и явно есть отличие между вратарями и полевыми игроками, мы изымем их из рассмотрения. Характеристики, которые начинаются с "goalkeeping" мы оставим, они могут помочь различать защитников, которые по долгу службы должны участвовать в защите ворот.

```{r}
goalkeepers <- str_detect(players_full$player_positions, "GK")
sum(goalkeepers)
```

Не так их и много.

Ещё одна проблема заключается в том, что выборка большая и может включать в себя потенциальные неоднородности, которые хотелось бы избежать. Например, в низших лигах границы между игроками могут быть размыты сильнее. Посмотрим, сколько игроков останется, если оставим только игроков команд высших лиг.

```{r}
top_leagues <- (players_full$league_level == 1)
sum(top_leagues, na.rm = TRUE)
```

Также, по этим признакам у нас не должно быть NA, уберём их позже, их немного.

Таким образом, остаётся столько футболистов:

```{r}
sum(top_leagues & !goalkeepers, na.rm = TRUE)
```

# Первичный анализ

Признаков много, поэтому проведём минимальный анализ. 
Сделаем два датафрейма, один с интересующими нас признаками, другой — с общей информацией об игроке, чтобы потом удобно было анализировать результат. NA уберём, как обещали.

```{r}
players <- players_full[top_leagues & !goalkeepers, skills_vars]
players <- na.omit(players)
dim(players)
players_info <- players_full[top_leagues & !goalkeepers, c(3,6,7,8,9,14,17,15,22,2)]
players_info <- na.omit(players_info)
dim(players_info)
num_players <- nrow(players)
```

## Summary по признакам {.tabset .tabset-pills}

```{r}
summary(players)
```

### Основные переменные

```{r}
players_m <- melt(players[,1:6]) 
p <- ggplot(data = players_m, aes(y=variable, x=value, fill = variable, alpha = 0.7)) + 
             geom_boxplot() + geom_violin() + scale_fill_manual(values = viridis(6)) + guides(fill = "none")
p 
```

### Атака

```{r}
players_m <- melt(players[,7:11]) 
p <- ggplot(data = players_m, aes(y=variable, x=value, fill = variable, alpha = 0.7)) + 
             geom_boxplot() + geom_violin() + scale_fill_manual(values = viridis(6)) + guides(fill = "none")
p 
```

### Опыт

```{r}
players_m <- melt(players[,12:16]) 
p <- ggplot(data = players_m, aes(y=variable, x=value, fill = variable, alpha = 0.7)) + 
             geom_boxplot() + geom_violin() + scale_fill_manual(values = viridis(6)) + guides(fill = "none")
p 
```

### Движение

```{r}
players_m <- melt(players[,17:21]) 
p <- ggplot(data = players_m, aes(y=variable, x=value, fill = variable, alpha = 0.7)) + 
             geom_boxplot() + geom_violin() + scale_fill_manual(values = viridis(6)) + guides(fill = "none")
p 
```

### Энергия

```{r}
players_m <- melt(players[,22:26]) 
p <- ggplot(data = players_m, aes(y=variable, x=value, fill = variable, alpha = 0.7)) + 
             geom_boxplot() + geom_violin() + scale_fill_manual(values = viridis(6)) + guides(fill = "none")
p 
```

### Ментальность

```{r}
players_m <- melt(players[,27:32]) 
p <- ggplot(data = players_m, aes(y=variable, x=value, fill = variable, alpha = 0.7)) + 
             geom_boxplot() + geom_violin() + scale_fill_manual(values = viridis(6)) + guides(fill = "none")
p 
```

### Защита

```{r}
players_m <- melt(players[,33:35]) 
p <- ggplot(data = players_m, aes(y=variable, x=value, fill = variable, alpha = 0.7)) + 
             geom_boxplot() + geom_violin() + scale_fill_manual(values = viridis(6)) + guides(fill = "none")
p 
```

### На воротах

```{r}
players_m <- melt(players[,36:40]) 
p <- ggplot(data = players_m, aes(y=variable, x=value, fill = variable, alpha = 0.7)) + 
             geom_boxplot() + geom_violin() + scale_fill_manual(values = viridis(6)) + guides(fill = "none")
p 
```

Как можно видеть, многие из приведённых графиков бимодальны, например, defending и attacking, что может быть хорошим знаком того, что кластеризация у нас получится (и может даже в нормальной модели).

Что касается вратарских качеств: их, по всей видимости можно (и нужно) убрать, они вряд ли нам помогут.

```{r}
players <- players[, -c(36:40)]
```


## Факторный анализ

Попробуем сократить размерность пространства признаков и посмотрим на biplot.

```{r}
res <- PCA(players, scale.unit = TRUE, graph = FALSE, ncp = 5)
fviz_pca_var(res)
res$var$coord %>% kbl() %>% kable_paper("hover", full_width = F, position = "left") %>%
    column_spec(2, color = "black", background = spec_color(abs(res$var$coord[,1]))) %>%
    column_spec(3, color = "black", background = spec_color(abs(res$var$coord[,2])))
```

```{r}
fviz_eig(res, addlabels = TRUE)
```

Первый фактор, по всей видимости, характеризует атакующую игру, а второй — защиту.
Первые две компоненты неплохо описывают дисперсию признаков, поэтому плоскость первых двух компонент весьма полезна для дальнейшей интерпретации.

Построим biplot и найдём некоторых игроков, чтобы интерпретировать полученный результат.

```{r}
fviz_pca_biplot(res,
                label = "all",
                col.ind = (viridis(3))[1],
                col.var = (viridis(3))[2],
                )
bestest <- c(1,4,3,5,29,15,23,16,61,47,56,115)
cbind(bestest, as.character(players_info$short_name[bestest]), as.character(players_info$club_position[bestest]))  %>% kbl() %>% kable_paper("hover", full_width = F, position = "left")
```

Нельзя сказать, что получилось однозначно (из-за полузащиты). С Месси (1), Неймаром (4) и Де Брюйне (5, атакующий полузащитник) всё логично, они в атаке.  
Махрез (47) сейчас полузащитник-вингер, однако помимо подключений к атакам, от этих полузащитников требуется защита их игровых зон от проходов крайних защитников и опорных соперника.
Киммих (15) тоже полузащитник. А вот Агуэро (23), вообще говоря, нападающий. 
Родри (56) - опорный полузащитник, поэтому немного странно, что он там, где есть (хотя, опять же, мы видим только двумерную картинку).
Впрочем, общая логика всё же присутствует.

Кстати, нумерация идёт по общему рейтингу, хорошо видим, что слева внизу индексы большие.

**Отчётливо видим, что есть облака точек; можно увидеть два крупных или три поменьше. **

# Кластеризация

Переходим к применению алгоритмов кластеризации.
Рассмотрим несколько известных алгоритмов:

1. Kohonen's Self-Organized Maps

2. Mclust

3. Иерархическая кластеризация

4. $k$ средних

5. DBscan

## SOM

Начнём с самоорганизующихся карт Кохонена, которые широко используются для уменьшения размерности данных.

```{r}
start_time <- Sys.time()
set.seed(56788)
data_matrix <- as.matrix(scale(players))
# Create the SOM Grid - you generally have to specify the size of the 
# training grid prior to training the SOM. Hexagonal and Circular 
# topologies are possible
som_grid <- somgrid(xdim = 20, ydim=20, topo="hexagonal")
# Finally, train the SOM, options for the number of iterations,
# the learning rates, and the neighbourhood are available
som_model <- som(data_matrix, 
        grid=som_grid, 
        rlen=3000, 
        alpha=c(0.05,0.01), 
        keep.data = TRUE)
end_time <- Sys.time()
end_time - start_time
```

### Выбор параметров

Начинаем с выбора сетки: все игроки расположатся в одной из 20х20 ячеек. Выбор размера базируется на колиичестве индивидов в каждой ячейке: их должно быть не менее 10 (см. дальше, как это увидеть). 

`rlen` отвечает за число итераций. Число итераций выбирается с использованием графика ниже. 


```{r}
plot(som_model, type="changes")
```

```{r}
plot(som_model, type="count")
```

На данной картинке показано, сколько индивидов находится в каждой из ячеек. Если смотреть на это как на карту, это аналог плотности населения. Красный цвет - в данном случае означает мало.
Если в одной ячейке много индивидов - значит оказалось, что они похожи друг на друга. При необходимости следует увеличивать размерность сетки, чтобы они стали различимыми. У нас есть одна ячейка с 70 индивидами

Это хорошо, что все игроки распределились по ячейкам более менее равномерно. Может быть нужно увеличить карту, чтобы получилось поменьше индивидов на ячейку, но пока оставим так.

### Карты {.tabset .tabset-pills}

Переходим к главным объектам - самим картам.

```{r, warning = FALSE}
#здесь просто текстовые лейблы делаем
labs_som = rep("", nrow(players))
labs_som[1:100] = abbreviate(players_info$short_name[1:100], 10)
labs_som[players_info$nationality == "Russia"] = as.character(players_info$short_name[players_info$nationality == "Russia"])
# это чтобы легче было раглядеть, можно экспортировать в рабочую папку pdf файл
# pdf()
# plot(som_model, type = "mapping", labels = labs_som, cex = 0.3)
# plot(som_model, type = "mapping", labels = labs_som, cex = 0.5, xlim = c(18,20), ylim = c(13,18))
# plot(som_model, type = "mapping", labels = labs_som, cex = 0.5, xlim = c(18,20), ylim = c(11,16))
```

#### Кто где {.tabset}

Для лучшего осознания того, что вообще на этих картах изображено, давайте покажем, в каких ячейках оказались футболисты топ уровня и наши соотечественники (они смешаны).

Здесь неплохо видно, что произошло. Все топовые игроки сместились в левую часть, однако хорошие защитники образовали кластер в правом верхнем углу. 

Если продолжать аналогию с картами, то 

- В левом вернем углу страна продвинутых полузащитников; 
- Тоже слева, но ближе к центру страна продвинутых нападающих;
- Справа вверху страна защитников;
- В центре универсальные молодые игроки. Продвинутых здесь несколько, но не международного класса.

С интерпретацией других мест на карте сложнее. Может станет лучше дальше, когда будем раскрашивать карту по признакам. 

Видим, что некоторая логика у такой карты есть. На вкладках можно чуть получше рассмотреть имена.

##### Общий вид

```{r, warning = FALSE}
plot(som_model, type = "mapping", labels = labs_som, cex = 0.5)
text(x = 1, y = 16, cex = 2, labels = "midfield", col = "green")
text(x = 1, y = 12, cex = 2, labels = "attack", col = "red")
text(x = 16, y = 14.5, cex = 2, labels = "defence", col = "blue")
```

##### Правая часть 

```{r, warning = FALSE}
plot(som_model, type = "mapping", labels = labs_som, cex = 0.5, xlim = c(16,17), ylim = c(14,18))
```

##### Левая часть 

```{r, warning = FALSE}
plot(som_model, type = "mapping", labels = labs_som, cex = 0.5, xlim = c(0,2), ylim = c(14,18))
plot(som_model, type = "mapping", labels = labs_som, cex = 0.5, xlim = c(0,3), ylim = c(10,13))
```

#### Карта с раскрасками

Раскрасим ячейки по признакам, а также разделим карту на части, максимально отдалённые друг от друга, с помощью  жирной линии (для этого используется иерархическая кластеризация, см. комментарии).

```{r, warning = FALSE}
coolBlueHotRed <- function(n, alpha = 1) {rainbow(n, end=4/6, alpha=alpha)[n:1]}
#k есть число желаемых групп для разделения
som.hc <- cutree(hclust(object.distances(som_model, "codes")), k=2)
#pdf("heatmapkoh")
par(mfrow = c(2,3))
plot(som_model, type = "property", 
     property = getCodes(som_model)[, 1], main = names(players)[1], palette.name = coolBlueHotRed)
add.cluster.boundaries(som_model, som.hc, lwd = 4)
plot(som_model, type = "property", 
     property = getCodes(som_model)[, 2], main = names(players)[2], palette.name = coolBlueHotRed)
add.cluster.boundaries(som_model, som.hc, lwd = 4)
plot(som_model, type = "property", 
     property = getCodes(som_model)[, 3], main = names(players)[3], palette.name = coolBlueHotRed)
add.cluster.boundaries(som_model, som.hc, lwd = 4)
plot(som_model, type = "property", 
     property = getCodes(som_model)[, 4], main = names(players)[4], palette.name = coolBlueHotRed)
add.cluster.boundaries(som_model, som.hc, lwd = 4)
plot(som_model, type = "property", 
     property = getCodes(som_model)[, 5], main = names(players)[5], palette.name = coolBlueHotRed)
add.cluster.boundaries(som_model, som.hc, lwd = 4)
plot(som_model, type = "property", 
     property = getCodes(som_model)[, 6], main = names(players)[6], palette.name = coolBlueHotRed)
add.cluster.boundaries(som_model, som.hc, lwd = 4)

```

Можно долго смотреть и анализировать, что получилось. 

Если посмотреть на раскраску по shooting, то неудивительно, что в левой части расположились практически все атакующие игроки. Поднимаясь слева наверх, видим улучшение по параметру передач, физической форме, темпу, и более высокие показатели по защите, при этом немного ухудшается shooting - чистая качественная полузащита. С защитой тоже всё понятно - лучшие - в правом верхнем углу.

И так далее...

## Model-based пример: `mclust`

Так как метод встречался ранее, пройдёмся по нему быстро.
Предполагается смесь нескольких нормальных распределений.

Будем использовать известную библиотеку `mclust()`, которая строит сразу множество вариантов моделей кластеризации.

```{r}
players_mclust <- Mclust(players, G = 1:4)
```

Параметр G отвечает за число кластеров. В данном случае будут строиться всевозможные модели от 1 до 4 кластеров.

Здесь посмотрим на тот выбор, который делает функция `mclust()`. Этот выбор основывается на посчитанных характеристиках качества модели BIC и ICL. Так как нам известно, что значения BIC и ICL есть случайные числа, можно посмотреть какие ещё варианты кластеризации близки по этим значениям.

```{r}
summary(players_mclust)
```

Метод выбрал разбиение на 9 кластеров, но это много для нас (убрал эту часть для скорости).

*Наш выбор* основан на совокупности факторов:

1. Значение байесовского информационного критерия модели (BIC) (больше --- лучше). Заметим, что значение BIC есть случайная величина, а значит будет весьма осмысленным рассмотреть несколько моделей с похожим BIC и разным числом кластеров и параметров.

2. Число кластеров и число оцениваемых параметров
Заметим здесь, что при сопоставимом значении BIC будем выбирать наиболее простую модель с наименьшим числом оцениваемых параметров, так как чем меньше параметров приходится оценивать, тем меньше будет дисперсия соответствующих оценок при фиксированном размере выборки. Мы хотели бы получить до четырёх кластеров.

Посмотрим на все BIC, построим график.
```{r}
playersBIC <- mclustBIC(players, G = 1:4)
bic_table <- playersBIC[,]
colnames(bic_table) <- colnames(playersBIC)
rownames(bic_table) <- 1:nrow(bic_table)
```

```{r}
bic_table[1:4,] %>% kbl() %>% kable_paper("hover")
plot(playersBIC, G = 1:4, legendArgs = list(x = "bottomright", ncol = 5))
```

Выбрали модель `VVV, 3` (VVV означает, что эллипсоиды распределений вообще никаким образом не совпадают (разный поворот, разный объём, и тд), это максимальное количество параметров)

```{r}
players_mclust <- Mclust(players, G = 3, modelNames = c("VVV"))
summary(players_mclust)
```

На основании наших предположений и графика с главными компонентами можем именовать классы. Построим биплот, чтобы оценить результат визуально.

```{r}
classes_mclust <- as.factor(players_mclust$classification)
table(players_mclust$classification)/num_players
levels(classes_mclust) <- c("Attack","Midfielder","Defence")
fviz_pca_biplot(res,
                label = "all",
                col.ind = classes_mclust,
                legend.title = "Players")
```

### Uncertainty

Для model based методов качество кластеров можно оценить с помощью меры `uncertainty`, которая вычисляется так: из единицы вычитается вероятность наиболее вероятного класса. Uncertainty должна быть малой для наибольшего числа индивидов.
Это весьма неплохо показывает, насколько классы пересекаются.

Мера встроена в полученный объект от mclust.
Посмотрим на различные квантили:

```{r}
quantile(players_mclust$uncertainty, probs =c(0.6, 0.7, 0.8, 0.9, 0.95, 0.975, 0.99, 0.995))
```

Видим, что у абсолютного большинства индивидов мера uncertainty мала (у $95\%$ индивидов мера меньше 0.25, что существенно лучше наихудшего возможного исхода в нашем случае $G=3$: $0.666$), что хорошо оценивает работу метода.

Чтобы можно было сравнивать все методы, посчитаем within SS/between SS
```{r}
# Subtract each value from the grand mean and get the number of observations in each cluster.
data.cent <- scale(players, scale=FALSE)
nrows <- table(classes_mclust)

TSS <- sum(data.cent^2)

WSS <- sapply(split(players, classes_mclust), function(x) sum(scale(x, scale=FALSE)^2))

BSS <- TSS - sum(WSS)

gmeans <- sapply(split(players, classes_mclust), colMeans)
means <- colMeans(players)
BSS <- sum(colSums((gmeans - means)^2) * nrows)

BSS/TSS
```

### Тест на игроках {.tabset}



#### Мир
Посмотрим на отдельныx игроков в таблице:

```{r, echo=FALSE}
players_top <- sort(c(bestest, 82, 37, 42, 11 , 38 , 14 , 24 , 30 , 84, 85))
cbind(rate = rownames(players[players_top,]), name = as.character(players_info$short_name[players_top]), position = as.character(players_info$club_position[players_top]), mclust = as.character(classes_mclust)[players_top]) %>% kbl() %>% kable_paper(full_width = F, "hover") %>%
    column_spec(4, color = "white", background = spec_color(as.numeric(classes_mclust[players_top]))) %>%
    column_spec(2, color = "blue", bold = T, link = players_info$player_url[players_top])
```

#### Россия

```{r}
russian <- (players_info$nationality == "Russia")
cbind(rate = rownames(players[russian,]), name = as.character(players_info$short_name[russian]), position = as.character(players_info$club_position[russian]), mclust = as.character(classes_mclust)[russian]) %>% kbl() %>% kable_paper(full_width = F, "hover") %>%
    column_spec(4, color = "white", background = spec_color(as.numeric(classes_mclust[russian]))) %>%
    column_spec(2, color = "blue", bold = T, link = players_info$player_url[russian])
```

Видим множество разумных совпадений.

## Про выбор расстояния

Вычисленные значения и рисунок ниже являются обоснованиями того, что нам может быть полезнее в данной задаче: использовать классическую евклидову метрику или же использовать метрику, основанную на корреляциях.

График для каждого футболиста представляет из себя значение рейтинга для каждого из 35 признаков.
Видим, что графики "похожи" между собой по форме для футболистов защиты. Аналогично для атакующих игроков. На форму общий уровень не влияет, что для нас важно.


```{r}
len_p <- length(names(players))
plot(1:len_p, players[1,], "l", col = "red", xlab = "variable", ylab = "points")
lines(1:len_p, players[2,], col = "red")
lines(1:len_p, players[1033,], col = "red", lty = 2)
lines(1:len_p, players[11,], col = "blue")
lines(1:len_p, players[12,], col = "blue")
lines(1:len_p, players[3180,], col = "blue", lty = 2)
cor_dist <- as.matrix(as.dist(1 - cor(t(players[c(1,2, 1033, 11,12, 3180),])), diag = TRUE, upper = TRUE))
cor_dist
eucl_dist <- as.matrix(dist(players[c(1,2, 1033, 11,12, 3180),], diag = TRUE, upper = TRUE))
eucl_dist/max(eucl_dist) #transform to new scale for comfort
legend("bottom", legend = c("Messi, 1", "Lewandowski, 2", "Smolov, 1180", "Casemiro, 15", "Van Dijk, 16", "Kudryashov, 3877"),  col = c("red", "red","red", "blue", "blue", "blue"), lwd = 1, lty = c(1,1,2,1,1,2))
```

Например, для наших целей важно, чтобы игроки обороны (вне зависимости от их рейтинга!) были близки друг к другу, но при этом далеки от игроков защиты. Именно такую ситуацию мы и наблюдаем при выборе корреляции в качестве расстояния: сформировались соответствующие плеяды.

Можно посмотреть, насколько корреляционная метрика здесь подходит лучше, посмотрев на межкластерное расстояние.

В случае корреляционной метрики:

```{r}
(sum(cor_dist[1:3, 1:3])+sum(cor_dist[4:6, 4:6]))/(sum(cor_dist[1:3, 4:6]) + sum(cor_dist[4:6, 1:3]))
```

В случае евклидовой:

```{r}
(sum(eucl_dist[1:3, 1:3])+sum(eucl_dist[4:6, 4:6]))/(sum(eucl_dist[1:3, 4:6]) + sum(eucl_dist[4:6, 1:3]))
```

Сумма расстояний между индивидами из тех же кластеров делится на сумму расстояний между объектами разных кластеров. Чем меньше, тем лучше. Видим, что корреляционная метрика несколько лучше.

## Иерархическая кластеризация

Здесь используем метрику корреляционную. Используем complete linkage, так как рассчитываем на сферичность кластеров (исходя из PCA).

```{r}
players_dist <- as.dist(1 - cor(t(players)))
players_hclust <- hclust(players_dist, method="complete")
plot(players_hclust, labels = labs_som, cex = 0.4, main = "Dendrogram (Complete linkage)")
```

```{r}
classes_hclust <- cutree(players_hclust, k = 3)
classes_hclust <- as.factor(classes_hclust)
levels(classes_hclust) <- c("Attack", "Defence", "Midfielder")
table(classes_hclust)/num_players
```

Кластер Midfielder стал значительно меньше (по сравнению с mclust). Поэтому учитывая размер класса, можно сказать, что логично выкинуть Midfielder и мы получим простую классификацию на атакующего и защиту.

```{r}
classes_hclust <- cutree(players_hclust, k = 2)
classes_hclust <- as.factor(classes_hclust)
levels(classes_hclust) <- c("Attack", "Defence")
table(classes_hclust)/num_players
```


Посмотрим на биплот, убедимся в том, что результат в целом похож на то, что мы видели ранее.

```{r}
fviz_pca_biplot(res,
                label = "all",
                col.ind = classes_hclust,
                legend.title = "Players")
```

Тоже вполне полезно и неплохо интерпретируемо.

**Если же сделать то же самое с обычной евклидовой метрикой, получим такие классы:**

```{r}
players_dist1 <- dist(players)
players_hclust1 <- hclust(players_dist1, method="complete")

classes_hclust1 <- cutree(players_hclust1, k = 3)
classes_hclust1 <- as.factor(classes_hclust1)
levels(classes_hclust1) <- c("Attack", "Good defence", "Not the best players")
table(classes_hclust1)/num_players

fviz_pca_biplot(res,
                label = "all",
                col.ind = classes_hclust1,
                legend.title = "Players")
```

Здесь получаем как раз ту проблему, о которой говорили: всё распределирось равномерно, однако слабые игроки ушли в третий класс. Если построить для двух кластеров, получим картинку, похожую на случай с корреляционной метрикой. Так что видим, что использование корреляционной метрики здесь даёт более устойчивый результат.

### Качество

Здесь опять же надо сделать замечание, что кластеры мы делали с помощью другого функционала (минимизировали корреляцию между индивидами), поэтому то, что приведено дальше — не совсем верно (но для сравнения с другими методами допустимо). 

```{r}
# Subtract each value from the grand mean and get the number of observations in each cluster.
data.cent <- scale(players, scale=FALSE)
nrows <- table(cutree(players_hclust, k = 2))

TSS <- sum(data.cent^2)

WSS <- sapply(split(players, classes_hclust), function(x) sum(scale(x, scale=FALSE)^2))

BSS <- TSS - sum(WSS)

gmeans <- sapply(split(players, classes_hclust), colMeans)
means <- colMeans(players)
BSS <- sum(colSums((gmeans - means)^2) * nrows)

BSS/TSS
```

Здесь функционал похуже, чем ранее с mclust.

## $k$-средних для трёх классов

```{r}
set.seed(28)
num_of_clust <- 3
players_kmeans <- kmeans(players, num_of_clust)
classes_kmeans <- players_kmeans$cluster

classes_kmeans <- as.factor(classes_kmeans)
levels(classes_kmeans) <- c("Attack", "Good defence and midfield", "Not the best players")
table(classes_kmeans)/num_players

fviz_pca_biplot(res,
                label = "all",
                col.ind = classes_kmeans,
                legend.title = "Players")
```

Результат как в случае иерархической кластеризации.

Всё же сравним с результатами mclust:
```{r}
table(classes_mclust, classes_kmeans)
```

Атака отделилась хорошо, видим устойчивость оценок. С остальными характеристиками не всё так хорошо.

Число BSS/TSS:
```{r}
players_kmeans$betweenss/(sum(players_kmeans$withinss)+players_kmeans$betweenss)
```

## DBSCAN

DBscan здесь сложно работать, ибо кластеры смешаны.

Для DBscan нужен оптимальный радиус окрестности — это когда абсолютное большинство точек имеют рядом $k$ соседей. 
Его можно определить приближённо с помощью kNN графика. 
Датасет у нас большой, но для начала попробуем взять 3 соседей (это станет min pts).

```{r}
dbscan::kNNdistplot(players, k =  3)
abline(h = 55, lty = 2)
```

Возьмём $\varepsilon = 55$. `minPts` это число точек в окрестности. Выбираем стандарт, чтобы сразу много не захватить.

```{r}
players_dbscan <- dbscan(players, eps = 60, minPts = 3)
```

Построим

```{r}
classes_dbscan <- players_dbscan$cluster
fviz_pca_biplot(res,
                label = "all",
                col.ind = factor(classes_dbscan),
                legend.title = "Players")
```

Получилось плохо, а число кластеров мы регулировать не можем.

Попытаем счастье, взяв метрику с корреляциями.

```{r}
dbscan::kNNdistplot(players_dist, k = 5)
abline(h = 0.2, lty = 2)
```

```{r}
players_dbscan <- dbscan(players_dist, eps = 0.2, minPts = 5)
classes_dbscan <- players_dbscan$cluster
```

```{r}
classes_dbscan <- players_dbscan$cluster
fviz_pca_biplot(res,
                label = "all",
                col.ind = factor(classes_dbscan),
                legend.title = "Players")
```

Всё одинаково плохо и это сложно интерпретировать.

# Таблица сравнения по методам {.tabset}

Если смотреть на таблицы и анализировать их, то mclust сработал очень неплохо, hclust с двумя классами и корреляционной метрикой тоже кластеризует достаточно хорошо.

## Мир

```{r}
cbind(rate = rownames(players[players_top,]), name = as.character(players_info$short_name[players_top]), position = as.character(players_info$club_position[players_top]), mclust = as.character(classes_mclust)[players_top],hclust = as.character(classes_hclust)[players_top], kmeans = as.character(classes_kmeans)[players_top], DBscan = as.character(classes_dbscan)[players_top] ) %>% kbl() %>% kable_paper(full_width = F, "hover") %>%
    column_spec(2, color = "blue", bold = T, link = players_info$player_url[players_top])
```

## Россия

```{r}
cbind(rate = rownames(players[russian,]), name = as.character(players_info$short_name[russian]), position = as.character(players_info$club_position[russian]), mclust = as.character(classes_mclust)[russian],hclust = as.character(classes_hclust)[russian], kmeans = as.character(classes_kmeans)[russian], DBscan = as.character(classes_dbscan)[russian] ) %>% kbl() %>% kable_paper(full_width = F, "hover") %>%
    column_spec(2, color = "blue", bold = T, link = players_info$player_url[russian])
```

# Выводы

В данной ситуации, когда кластеры перемешаны, явно выигравает model based подход, с помощью mclust.
Остальные методы сильно зависят от выбора метрики.
SOM помогает получать некоторые интерпретации, однако со сходимостью могут быть проблемы.



