---
title: "Probabilistic LSA. Тематическое моделирование."
output:
    html_document:
        #folding of code
        code_folding: show
        #highliting of the code
        highlight: tango
        #theme of the document (see bootswatch.com)
        #other nice variants:
        ##“default”, “cerulean”, “journal”, “flatly”, “darkly”,
        ##“readable”, “spacelab”, “united”, “cosmo”, “lumen”,
        ##“paper”, “sandstone”, “simplex”, “yeti”
        theme: readable
        #table of contents
        toc: yes
        #floating table of contents
        toc_float:
          #collapsed subsections
          collapsed: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# set options
options(stringsAsFactors = F)        
options("scipen" = 100, "digits" = 4) 
library(knitr) 
library(kableExtra) 
library(DT)
library(tm)
library(topicmodels)
library(reshape2)
library(ggplot2)
library(wordcloud)
library(pals)
library(flextable)
```

# Введение 

В данной работе мы пытались провести тематическое моделирование на всех 114 сурах корана.
Сразу вынуждены сказать, что попытка оказалась достаточно неудачной, однако сам процесс и используемые функции должны быть полезными.

# Подготовка

Здесь мы устанавливаем рабочую папку (та, в которой содержатся текстовые файлы).
Затем записываем все содержание папки в объект корпуса, который позволяет вернуться к исходникам текста в любой момент, вне зависимости от того, какие преобразования мы сделали.
В конце показываем, как можно посмотреть на исходный текст.

```{r, warning=FALSE}
setwd("~/Documents/GitHub/STAT-ML/clustering thematic modeling/practice/qaran")
quran <- VCorpus(DirSource(encoding = "latin1"),
                readerControl = list(language = "en"))
inspect(quran[[1]])
```

## Обработка текста

Один из самых сложных этапов — подготовка текста. Подгрузим stopwords, которые не помогут нам в поиске тематики.

```{r}
english_stopwords <- readLines("https://slcladal.github.io/resources/stopwords_en.txt", encoding = "UTF-8")
head(english_stopwords, 10)
```

Понятно, почему не помогут. Если что, для русского тоже несложно найти стоп слова.

Далее используем целый пакет функций, которые приводят текст в удобное для обработки состояние.
Заметим, что мы удаляем некоторые специфические для Корана слова, которые встречаются слишком часто и просто перекрывают весь возможный контекст.

```{r}
library(SnowballC)
processedCorpus <- tm_map(quran, content_transformer(tolower))
processedCorpus <- tm_map(processedCorpus, removeWords, english_stopwords)
#уберем слишком часто встречающиеся слова со слишком общим смыслом
processedCorpus <- tm_map(processedCorpus, removeWords, c("lord", "god", "messenger", "day"))
processedCorpus <- tm_map(processedCorpus, removePunctuation, preserve_intra_word_dashes = TRUE)
processedCorpus <- tm_map(processedCorpus, removeNumbers)
processedCorpus <- tm_map(processedCorpus, stemDocument, language = "en")
processedCorpus <- tm_map(processedCorpus, stripWhitespace)
```

# Topic Modelling

## Создание DTM

Создаём матрицу термов. minimumFrequency выбирается с учётом двух моментов: слишком маленькое значение даст слишком много термов, слишком большое — слишком мало. В данном случае, если слово встретилось более 5 раз, оно попадает в матрицу.

```{r}
minimumFrequency <- 5
DTM <- DocumentTermMatrix(processedCorpus, control = list(bounds = list(global = c(minimumFrequency, Inf))))
sel_idx <- slam::row_sums(DTM) > 0
DTM <- DTM[sel_idx, ]
# количество документов и термов
dim(DTM)
```

## Моделирование

Используем метод Гиббса LDA, см.конспект.

Выберем 5 тем. Четких рекомендаций нет. Чем больше, тем сложнее их интерпретировать, так как каждая тема характеризуется набором слов и термы начинают повторяться. Если взять слишком мало, то темы смешаются.
Например, для анализа обращения президента по параграфам использовали 20 тем.

Здесь по идее должно быть несколько главных тем, вроде прощения, наказания, описания бога и его деательности, наставления, и может быть что-то про неверующих. Поэтому выбрал 5.

Выбрали 1500 итераций. Для больших данных это может быть многовато, но есть возможность ускориться, увеличив minimum frequency.

```{r}
# number of topics
K <- 5
set.seed(9)
topicModel <- LDA(DTM, K, method="Gibbs", control=list(iter = 1500, verbose = 100))
```

## Результаты

`tmResult` — это главный объект для дальнейшего анализа. У нас здесь указаны несколько первых текстов и вероятности тем для них.

```{r}
tmResult <- posterior(topicModel)
beta <- tmResult$terms   
theta <- tmResult$topics 
head(tmResult$topics)
```

Конечно, пока непонятно, что это за темы. Посмотрим не первые 3 термa для каждой темы. Пусть их название состоит из этих термов.

```{r}
terms(topicModel, k = 3)
top3termsPerTopic <- terms(topicModel, 3)
topicNames <- apply(top3termsPerTopic, 2, paste, collapse=".")
topicNames
```

Первые слова должны отражать тему наилучшим образом.
В принципе, осмысленные названия для тем вытащить можно.

## Проверка и визуализация {.tabset}

Посмотрим на документы, у которых максимумы по каждой из этих тем.
Характерные представители тем помогут убедиться в адекватности модели.

### Create

```{r}
cr <- which.max(tmResult$topics[,1])
cr
tmResult$topics[cr,]
```

Милостивый научил Корану, создал человека и научил его изъясняться. Солнце и Луна движутся согласно рассчитанному порядку. Травы (или звезды) и деревья совершают поклоны. Он возвысил небо и установил весы, чтобы вы не преступали границы дозволенного на весах. Взвешивайте беспристрастно и не занижайте вес. Он установил землю для тварей. На ней есть фрукты и финиковые пальмы с чашечками (или волокнами), а также злаки с листьями и травы благоуханные. Какую же из милостей вашего Господа вы считаете ложью?


### Disbelieve

```{r}
di <- which.max(tmResult$topics[,2])
di
tmResult$topics[di,]
```

Аллах и Его Посланник освобождены от договоров, которые вы заключили с многобожниками. Посему странствуйте по земле в течение четырёх месяцев и знайте, что вам (многобожникам) не сбежать от Аллаха и что Аллах опозорит неверующих. В день великого паломничества Аллах и Его Посланник объявят людям о том, что Аллах и Его Посланник отрекаются от многобожников. Если вы раскаетесь, то тем лучше для вас. Если же вы отвернётесь, то знайте, что вам не сбежать от Аллаха. Обрадуй же вестью о мучительных страданиях неверующих. Это не относится к тем многобожникам, с которыми вы заключили договор и которые после этого ни в чём его не нарушили и никому не помогали против вас. Соблюдайте же договор с ними до истечения его срока. Воистину, Аллах любит богобоязненных.


### Believe

```{r}
be <- which.max(tmResult$topics[,3])
be
tmResult$topics[be,]
```

О Пророк! Бойся Аллаха и не повинуйся неверующим и лицемерам. Воистину, Аллах - Знающий, Мудрый. Следуй тому, что внушается тебе в откровении от твоего Господа. Воистину, Аллах ведает о том, что вы совершаете. Уповай на Аллаха, и довольно того, что Аллах является Попечителем и Хранителем! Аллах не даровал человеку двух сердец в одном теле. Он не сделал вашими матерями тех ваших жён, которых вы объявляете запретными для себя, и не сделал ваших приёмных сыновей вашими сыновьями. Это - всего лишь слова из ваших уст. Аллах же глаголет истину и наставляет на прямой путь. Зовите их (приемных детей) по именам их отцов. Это более справедливо перед Аллахом. Если же вы не знаете их отцов, то они являются вашими братьями по вере и вашими близкими. Не будет на вас греха, если вы совершите ошибку, если только вы не вознамерились совершить такое в сердце. Аллах - Прощающий, Милосердный. Пророк ближе к верующим, чем они сами, а его жёны - их матери. В соответствии с предписанием Аллаха, кровные родственники ближе друг к другу, чем верующие и мухаджиры, если только вы не сделаете добро своим друзьям. Так было записано в Писании (Хранимой скрижали).


### People, Truth

```{r}
petr <- which.max(tmResult$topics[,4])
petr
tmResult$topics[petr,]
```

Алиф. Лам. Ра. Это – аяты ясного Писания. Воистину, Мы ниспослали его в виде Корана на арабском языке, чтобы вы могли понять его. Мы рассказываем тебе самое прекрасное повествование, внушая тебе в откровении этот Коран, хотя прежде ты был одним из тех, кто ничего не ведал об этом. Вот Йусуф (Иосиф) сказал своему отцу: "О мой отец! Я видел одиннадцать звёзд, солнце и луну. Я видел, как они поклонились мне". Он сказал: "О сын мой! Не рассказывай этот сон своим братьям, а не то они замыслят против тебя дурное. Воистину, сатана – явный враг человеку. Твой Господь изберёт тебя, научит тебя толковать сны и одарит совершенной милостью тебя и род Йакуба (Иакова), подобно тому, как ещё раньше Он одарил совершенной милостью твоих отцов Ибрахима (Авраама) и Исхака (Исаака). Воистину, твой Господь – Знающий, Мудрый".


### Earth, Heaven

```{r}
eahe <- which.max(tmResult$topics[,5])
eahe
tmResult$topics[eahe,]
```


Он привёл вам притчу о вас самих. Есть ли среди невольников, которыми овладели ваши десницы, совладельцы того, чем Мы наделили вас, которые имеют с вами одинаковые права на это и которых вы опасаетесь так, как опасаетесь друг друга? Так Мы разъясняем знамения для людей разумеющих. Но нет! Беззаконники потакают своим желаниям безо всякого знания. Кто наставит на прямой путь тех, кого Аллах ввёл в заблуждение? Не будет для них помощников! Обрати свой лик к религии, исповедуя единобожие. Таково врождённое качество, с которым Аллах сотворил людей. Творение Аллаха не подлежит изменению. Такова правая вера, но большинство людей не знают этого. Обращайтесь к Нему с раскаянием, бойтесь Его, совершайте намаз и не будьте в числе многобожников, в числе тех, которые внесли раскол в свою религию и стали сектами, каждая из которых радуется тому, что имеет.


### Визуализация

```{r}
exampleIds <- c(cr, di, be, petr, eahe)
N <- length(exampleIds)
topicProportionExamples <- theta[exampleIds,]
colnames(topicProportionExamples) <- topicNames
vizDataFrame <- melt(cbind(data.frame(topicProportionExamples), document = factor(1:N)), variable.name = "topic", id.vars = "document")  
ggplot(data = vizDataFrame, aes(topic, value, fill = document), ylab = "proportion") + 
  geom_bar(stat="identity") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +  
  coord_flip() +
  facet_wrap(~ document, ncol = N)
```


